{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #pandas for data analysis\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Privacy Law courpus metadata file imported\n",
    "df = pd.read_csv(\"/content/privacy_law_corpus_metadata.csv\")\n",
    "\n",
    "#Drop the unknown column\n",
    "#df.drop(['unknown'], axis=1)\n",
    "\n",
    "#strip leading and trailing spaces from the values\n",
    "df = df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "\n",
    "#save cleaned data to a new csv file\n",
    "df.to_csv('cleaned_privacy_law_corpus_metadata.csv', index=False)\n",
    "\n",
    "#remove any whitespaces in the column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "#preview results\n",
    "df.head()\n",
    "\n",
    "#validation of column names\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace corresponding values to 'Originally in other languages'\n",
    "df['Translation Type'] = df['Translation Type'].apply(lambda x: 'Originally in other languages' if x == '[Not Applicable]' else x)\n",
    "\n",
    "# Replace corresponding values to 'Originally English'\n",
    "df.loc[(df['Original Language'] == 'English') & (df['Translation Type'] == 'Originally in other languages'), 'Translation Type'] = 'Originally English'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency count of \"Translation_Type\" column\n",
    "valuecount_translation_type = df['Translation Type'].value_counts()\n",
    "\n",
    "#save it to a new frame\n",
    "valuecount_translation_type_df = valuecount_translation_type.to_frame()\n",
    "\n",
    "#reset column names\n",
    "valuecount_translation_type_df = valuecount_translation_type_df.reset_index()\n",
    "\n",
    "#add custom column names: Translation Type, No. of Documents\n",
    "valuecount_translation_type_df.columns = ['Translation Type', 'No. of Documents']\n",
    "\n",
    "#Add % of Total column\n",
    "valuecount_translation_type_df['% of Total'] = (valuecount_translation_type_df['No. of Documents'] / valuecount_translation_type_df['No. of Documents'].sum()) * 100\n",
    "\n",
    "#Format Total column values upto two decimals\n",
    "valuecount_translation_type_df['% of Total'] = valuecount_translation_type_df['% of Total'].round(2)\n",
    "\n",
    "#Print the dataframe\n",
    "print(valuecount_translation_type_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace special values with None\n",
    "#NYIP = Not yet in effect\n",
    "df[\"First Privacy Law\"] = df[\"First Privacy Law\"].replace(\"NYIF\", None)\n",
    "df[\"First Privacy Law\"] = df[\"First Privacy Law\"].replace(\"[None]\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the column 'First Privacy Law' in datatime format and store it in a new column 'date_created'\n",
    "df['date_created'] = pd.to_datetime(df['First Privacy Law'])\n",
    "df['date_created']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract year from date_created column\n",
    "df['year'] = pd.DatetimeIndex(df['date_created']).year\n",
    "\n",
    "# group by year and get its frequency\n",
    "year_freq = df.groupby('year').size().reset_index(name='frequency')\n",
    "\n",
    "# sort year_freq by year in ascending order\n",
    "year_freq = year_freq.sort_values(by='year')\n",
    "\n",
    "# add cumulative frequency column\n",
    "year_freq['cumulative_frequency'] = year_freq['frequency'].cumsum()\n",
    "\n",
    "# print the resulting dataframe\n",
    "print(year_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a figure and axis objects\n",
    "fig, ax1 = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# plot the cumulative number of privacy documents enacted on the left axis\n",
    "line1, = ax1.plot(year_freq['year'], year_freq['cumulative_frequency'], color='blue')\n",
    "ax1.set_ylabel('Cumulative # Privacy Documents Enacted', color='blue')\n",
    "ax1.yaxis.set_major_locator(ticker.MultipleLocator(100))\n",
    "\n",
    "# create a second axis object for the number of privacy documents enacted per year\n",
    "ax2 = ax1.twinx()\n",
    "line2, = ax2.plot(year_freq['year'], year_freq['frequency'], color='red')\n",
    "ax2.set_ylabel('# Privacy Documents Enacted', color='red')\n",
    "ax2.yaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "\n",
    "# set the x-axis label and tick format\n",
    "ax1.set_xlabel('Year Enacted')\n",
    "ax1.xaxis.set_major_locator(ticker.MultipleLocator(10))\n",
    "# set the x-axis limits to start from the minimum year and increase by 10 years\n",
    "#ax1.set_xlim(year_freq['year'].min(), 2022, 10)\n",
    "ax1.set_xlim(year_freq['year'].min(), year_freq['year'].max(), 10)\n",
    "\n",
    "# add a title to the plot\n",
    "plt.title('Privacy Laws enacted overtime', fontsize=16)\n",
    "\n",
    "# add a legend to the plot\n",
    "ax1.legend(handles=[line1, line2], labels=['Cumulative # Privacy Documents', '# Privacy Documents'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# create a figure and axis objects\n",
    "fig, ax1 = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# plot the cumulative number of privacy documents enacted on the left axis\n",
    "line1, = ax1.plot(year_freq['year'], year_freq['cumulative_frequency'], color='blue')\n",
    "ax1.set_ylabel('Cumulative # Privacy Documents Enacted', color='blue', fontsize=14)  # Increase font size here\n",
    "ax1.yaxis.set_major_locator(ticker.MultipleLocator(100))\n",
    "\n",
    "# create a second axis object for the number of privacy documents enacted per year\n",
    "ax2 = ax1.twinx()\n",
    "line2, = ax2.plot(year_freq['year'], year_freq['frequency'], color='red')\n",
    "ax2.set_ylabel('# Privacy Documents Enacted', color='red', fontsize=14)  # Increase font size here\n",
    "ax2.yaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "\n",
    "# set the x-axis label and tick format\n",
    "ax1.set_xlabel('Year Enacted', fontsize=14)  # Increase font size here\n",
    "ax1.xaxis.set_major_locator(ticker.MultipleLocator(10))\n",
    "ax1.tick_params(axis='both', labelsize=12)  # Increase tick label font size\n",
    "\n",
    "# set the x-axis limits to start from the minimum year and increase by 10 years\n",
    "ax1.set_xlim(year_freq['year'].min(), year_freq['year'].max(), 10)\n",
    "\n",
    "# add a title to the plot\n",
    "plt.title('Privacy Laws enacted over time', fontsize=16)  # Increase font size here\n",
    "\n",
    "# add a legend to the plot\n",
    "ax1.legend(handles=[line1, line2], labels=['Cumulative # Privacy Documents', '# Privacy Documents'], loc='upper left')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a figure and axis objects\n",
    "fig, ax1 = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# plot the cumulative number of laws enacted on the left axis\n",
    "ax1.plot(year_freq['year'], year_freq['cumulative_frequency'], color='blue')\n",
    "ax1.set_ylabel('Cumulative # Privacy Documents Enacted', color='blue')\n",
    "ax1.yaxis.set_major_locator(ticker.MultipleLocator(100))\n",
    "\n",
    "# create a second axis object for the number of laws enacted per year\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(year_freq['year'], year_freq['frequency'], color='red')\n",
    "ax2.set_ylabel('# Privacy Documents Enacted', color='red')\n",
    "ax2.yaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "\n",
    "# set the x-axis label and tick format\n",
    "ax1.set_xlabel('Year Enacted')\n",
    "ax1.xaxis.set_major_locator(ticker.MultipleLocator(10))\n",
    "# set the x-axis limits to start from the minimum year and increase by 10 years\n",
    "#ax1.set_xlim(year_freq['year'].min(), 2022, 10)\n",
    "ax1.set_xlim(2000, 2020, 10)\n",
    "\n",
    "# add a title to the plot\n",
    "plt.title('Privacy Laws enacted overtime - 21st Century')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# create a figure and axis objects\n",
    "fig, ax1 = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# plot the cumulative number of laws enacted on the left axis\n",
    "ax1.plot(year_freq['year'], year_freq['cumulative_frequency'], color='blue')\n",
    "ax1.set_ylabel('Cumulative # Privacy Documents Enacted', color='blue', fontsize=14)  # Increase font size here\n",
    "ax1.yaxis.set_major_locator(ticker.MultipleLocator(100))\n",
    "\n",
    "# create a second axis object for the number of laws enacted per year\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(year_freq['year'], year_freq['frequency'], color='red')\n",
    "ax2.set_ylabel('# Privacy Documents Enacted', color='red', fontsize=14)  # Increase font size here\n",
    "ax2.yaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "\n",
    "# set the x-axis label and tick format\n",
    "ax1.set_xlabel('Year Enacted', fontsize=14)  # Increase font size here\n",
    "ax1.xaxis.set_major_locator(ticker.MultipleLocator(10))\n",
    "ax1.tick_params(axis='both', labelsize=12)  # Increase tick label font size\n",
    "\n",
    "# set the x-axis limits to start from the minimum year and increase by 10 years\n",
    "ax1.set_xlim(2000, 2020, 10)\n",
    "\n",
    "# add a title to the plot\n",
    "plt.title('Privacy Laws enacted over time - 21st Century', fontsize=16)  # Increase font size here\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming your DataFrame is called df\n",
    "df['jurisdiction_type'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "State = np.array(['California'])\n",
    "Special_Administrative_Regions = np.array(['Hong Kong SAR',  'Macao SAR', 'BES Islands (Bonaire, Sint Estatius and Saba)'])\n",
    "Special_Economic_Zones = np.array(['Abu Dhabi Global Market', 'Dubai Healthcare City (DHCC)', 'Dubai International Financial Centre', 'Qatar Financial Centre'])\n",
    "International_Organizations = np.array(['European Union', 'African Union', 'Asia-Pacific Economic Cooperation', 'United Nations'])\n",
    "Crown_Dependencies = np.array(['Isle of Man', 'Guernsey', 'Jersey'])\n",
    "British_Overseas_Territories = np.array(['Bermuda', 'Cayman Islands', 'Gibraltar'])\n",
    "Intergovernmental_Organizations = np.array(['CoE + Uruguay, Mauritius, Senegal, Tunisia', 'European Union + United States', 'Switzerland + United States', 'United States + 23 others'])\n",
    "Countries = np.array(['Antigua & Barbuda', 'Cura√ßao', 'S√£o Tom√© and Principe', 'Bosnia & Herzegovina', 'Cape Verde', 'Democratic Republic of the Congo', 'East Timor', 'Korea, South', 'Macedonia (FYROM)', 'Phillippines', 'St. Lucia', 'St. Vincent & Grenadines', 'Trinidad & Tobago'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over each row in your DataFrame\n",
    "for i, row in df.iterrows():\n",
    "    # check if the jurisdiction name is in any of the arrays\n",
    "    if row['Jurisidction Name'] in State:\n",
    "        df.at[i, 'jurisdiction_type'] = 'State'\n",
    "    elif row['Jurisidction Name'] in Special_Administrative_Regions:\n",
    "        df.at[i, 'jurisdiction_type'] = 'Special Administrative Regions'\n",
    "    elif row['Jurisidction Name'] in Special_Economic_Zones:\n",
    "        df.at[i, 'jurisdiction_type'] = 'Special Economic Zones'\n",
    "    elif row['Jurisidction Name'] in International_Organizations:\n",
    "        df.at[i, 'jurisdiction_type'] = 'International Organizations'\n",
    "    elif row['Jurisidction Name'] in Crown_Dependencies:\n",
    "        df.at[i, 'jurisdiction_type'] = 'Crown Dependencies'\n",
    "    elif row['Jurisidction Name'] in British_Overseas_Territories:\n",
    "        df.at[i, 'jurisdiction_type'] = 'British Overseas Territories'\n",
    "    elif row['Jurisidction Name'] in Intergovernmental_Organizations:\n",
    "        df.at[i, 'jurisdiction_type'] = 'Intergovernmental Organizations'\n",
    "    elif row['Jurisidction Name'] in Countries:\n",
    "        df.at[i, 'jurisdiction_type'] = 'Countries'\n",
    "    else:\n",
    "        df.at[i, 'jurisdiction_type'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = df['jurisdiction_type'].value_counts(dropna=False)\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming your DataFrame is called df\n",
    "def get_jurisdiction_type(jurisdiction_name):\n",
    "    try:\n",
    "        country = pycountry.countries.search_fuzzy(jurisdiction_name)[0]\n",
    "        return 'Countries'\n",
    "    except LookupError:\n",
    "        return None\n",
    "\n",
    "#df['jurisdiction_type'] = df['Jurisidction Name'].apply(get_jurisdiction_type)\n",
    "df.loc[df['jurisdiction_type'].isna(), 'jurisdiction_type'] = df.loc[df['jurisdiction_type'].isna(), 'Jurisidction Name'].apply(get_jurisdiction_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = df['jurisdiction_type'].value_counts(dropna=False)\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[df['jurisdiction_type'].isnull(), 'Jurisidction Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_composition = {'Jurisdiction Type': [],\n",
    "        'Coverage Type': [],\n",
    "        '#Unique Jurisdictions': [],\n",
    "        '#Documents': [],\n",
    "        'Examples': []}\n",
    "cc = pd.DataFrame(corpus_composition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'jurisdiction_type' and count the unique values in 'jurisdiction_name'\n",
    "unique_counts = df.groupby('jurisdiction_type')['Jurisidction Name'].nunique()\n",
    "\n",
    "# Count the frequency of each unique value in the 'jurisdiction_type' column of df\n",
    "jurisdiction_counts = df['jurisdiction_type'].value_counts()\n",
    "\n",
    "# Iterate over the unique values and their counts\n",
    "for jurisdiction_type, count in jurisdiction_counts.items():\n",
    "    # Add the value, its count, and the unique count to the 'corpus_composition' DataFrame\n",
    "    cc = cc.append({'Jurisdiction Type': jurisdiction_type,\n",
    "                    '#Documents': count,\n",
    "                    '#Unique Jurisdictions': unique_counts[jurisdiction_type]},\n",
    "                   ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array of replacement values\n",
    "Coverage_Type = ['N', 'N', 'N', 'S/P', 'I', 'S/P', 'I', 'S/P']\n",
    "Examples = ['Albania', 'Cayman Islands', 'Isle of Man', 'Macau', 'United Nations', 'Qatar Financial Centre', 'US + 23 Countries', 'California (USA)']\n",
    "\n",
    "# replace the NaN values in column 'A' with values from the replacement_array\n",
    "cc['Coverage Type'] = cc['Coverage Type'].fillna(pd.Series(Coverage_Type))\n",
    "cc['Examples'] = cc['Examples'].fillna(pd.Series(Examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the unique values of the 'Name' column and add them to a list\n",
    "unique_countries = df['Jurisidction Name'].unique().tolist()\n",
    "print(unique_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry\n",
    "\n",
    "countries = []\n",
    "for country_name in unique_countries:\n",
    "    try:\n",
    "        country = pycountry.countries.search_fuzzy(country_name)[0]\n",
    "        countries.append(country.name)\n",
    "    except LookupError:\n",
    "        pass\n",
    "\n",
    "print(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pycountry_convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry_convert as pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new column with country codes\n",
    "df['country code'] = df['Jurisidction Name'].map(country_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df = df[['country code']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import json\n",
    "\n",
    "# Drop rows with NaN values in 'country_code' column\n",
    "country_df = country_df.dropna(subset=['country code'])\n",
    "\n",
    "country_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for NaN values in 'country_code' column\n",
    "if country_df['country code'].isna().any():\n",
    "    print('There are NaN values in the \"country_code\" column')\n",
    "else:\n",
    "    print('No NaN values in the \"country_code\" column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the frequency of each country code\n",
    "country_freq = country_df['country code'].value_counts().reset_index()\n",
    "\n",
    "# rename the columns to 'country_code' and 'frequency'\n",
    "country_freq.columns = ['country code', 'frequency']\n",
    "\n",
    "# print the new dataframe\n",
    "country_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "# Generate choropleth map using built-in country codes\n",
    "fig = px.choropleth(country_freq, locations='country code', color='frequency',\n",
    "                    scope='world', # set the map's scope to 'world'\n",
    "                    projection='equirectangular',\n",
    "                    color_continuous_scale='blues') # set the map's projection\n",
    "\n",
    "fig.update_layout(geo=dict(showframe=False))\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
